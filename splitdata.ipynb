{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1181e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from paths import PROCESSED_DATA_DIR, SPLITS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feaa122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pq.read_table(PROCESSED_DATA_DIR).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ed27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segments, a smaller dataframe, with one row per segment, looking like this: MMSI, Segment\n",
    "segments = df[['MMSI','Segment']].drop_duplicates()\n",
    "\n",
    "# First split: train vs temp (train 70%, temp 30%)\n",
    "train_segments, temp_segments = train_test_split(\n",
    "    segments,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Second split: temp -> validation and test (each 15% of total)\n",
    "val_segments, test_segments = train_test_split(\n",
    "    temp_segments,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fb18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#give train_segments a new column 'segment_id' with a unique id for each row starting from 0\n",
    "train_segments['segment_id'] = range(len(train_segments))\n",
    "val_segments['segment_id'] = range(len(val_segments))\n",
    "test_segments['segment_id'] = range(len(test_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41246fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.merge(train_segments[['MMSI','Segment', 'segment_id']], on=['MMSI','Segment'])\n",
    "val_df   = df.merge(val_segments[['MMSI','Segment', 'segment_id']], on=['MMSI','Segment'])\n",
    "test_df  = df.merge(test_segments[['MMSI','Segment', 'segment_id']], on=['MMSI','Segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c3ebb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataframe length: 52135706\n",
      "Validation dataframe length: 10771374\n",
      "Test dataframe length: 11205602\n"
     ]
    }
   ],
   "source": [
    "#print length of each dataframe\n",
    "print(\"Train dataframe length:\", len(train_df))\n",
    "print(\"Validation dataframe length:\", len(val_df))\n",
    "print(\"Test dataframe length:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing: Remove segments with NaN values in COG or SOG from train_df, val_df and test_df\n",
    "for df_name in ['train_df', 'val_df', 'test_df']:\n",
    "    df = globals()[df_name]  # get the DataFrame by name\n",
    "    # Find bad segments\n",
    "    bad_segments = df.loc[df['COG'].isna() | df['SOG'].isna(), 'segment_id'].unique()\n",
    "    # Drop all rows from bad segments\n",
    "    globals()[df_name] = df[~df['segment_id'].isin(bad_segments)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f79a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the Segment column from train_df, val_df and test_df\n",
    "train_df = train_df.drop(columns=['Segment'])\n",
    "val_df   = val_df.drop(columns=['Segment'])\n",
    "test_df  = test_df.drop(columns=['Segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f039124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort train_df, val_df and test_df by segment_id and Timestamp\n",
    "train_df = train_df.sort_values(by=['segment_id', 'Timestamp'])\n",
    "val_df   = val_df.sort_values(by=['segment_id', 'Timestamp'])\n",
    "test_df  = test_df.sort_values(by=['segment_id', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22371dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the removal of bad segments, update segment ids to be consecutive\n",
    "def update_segment_ids(df):\n",
    "    unique_segment_ids = df['segment_id'].unique()\n",
    "    id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_segment_ids)}\n",
    "    df['segment_id'] = df['segment_id'].map(id_mapping)\n",
    "    return df\n",
    "train_df = update_segment_ids(train_df)\n",
    "val_df   = update_segment_ids(val_df)\n",
    "test_df  = update_segment_ids(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14b8fc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train segment IDs: [0 1 2 3 4 5 6 7 8 9]\n",
      "Validation segment IDs: [0 1 2 3 4 5 6 7 8 9]\n",
      "Test segment IDs: [0 1 2 3 4 5 6 7 8 9]\n",
      "Train dataframe length: 39850008\n",
      "Validation dataframe length: 8337407\n",
      "Test dataframe length: 8522851\n",
      "Train segment ID range: 0 - 59517\n",
      "Validation segment ID range: 0 - 12846\n",
      "Test segment ID range: 0 - 12701\n",
      "                   Timestamp   Latitude  Longitude       SOG   COG       MMSI  \\\n",
      "35548948 2024-03-18 00:04:59  56.258310   7.193732  6.121884  38.6  235437000   \n",
      "35548949 2024-03-18 00:05:02  56.258477   7.194003  6.121884  41.4  235437000   \n",
      "35548950 2024-03-18 00:13:34  56.280622   7.227172  6.173328  40.8  235437000   \n",
      "35548951 2024-03-18 00:23:54  56.307090   7.267263  6.121884  42.5  235437000   \n",
      "35548952 2024-03-18 00:25:50  56.312018   7.274668  6.173328  41.0  235437000   \n",
      "\n",
      "          segment_id  \n",
      "35548948           0  \n",
      "35548949           0  \n",
      "35548950           0  \n",
      "35548951           0  \n",
      "35548952           0  \n",
      "                           Timestamp      Latitude     Longitude  \\\n",
      "count                       39850008  3.985001e+07  3.985001e+07   \n",
      "mean   2024-07-04 10:24:59.662942976  5.601492e+01  1.082745e+01   \n",
      "min              2024-01-01 00:00:00  5.049804e+01  0.000000e+00   \n",
      "25%              2024-04-16 11:05:01  5.509445e+01  9.889317e+00   \n",
      "50%              2024-07-07 20:50:04  5.573571e+01  1.091963e+01   \n",
      "75%              2024-09-21 13:10:07  5.700406e+01  1.192933e+01   \n",
      "max              2024-12-31 23:59:07  5.988638e+01  1.999996e+01   \n",
      "std                              NaN  1.073428e+00  1.860596e+00   \n",
      "\n",
      "                SOG           COG    segment_id  \n",
      "count  3.985001e+07  3.985001e+07  3.985001e+07  \n",
      "mean   2.038028e+00  1.808947e+02  2.978648e+04  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    0.000000e+00  8.420000e+01  1.494800e+04  \n",
      "50%    5.144440e-02  1.879000e+02  2.987100e+04  \n",
      "75%    4.372774e+00  2.713000e+02  4.462300e+04  \n",
      "max    2.572220e+01  3.599000e+02  5.951700e+04  \n",
      "std    2.772754e+00  1.079928e+02  1.719394e+04  \n"
     ]
    }
   ],
   "source": [
    "#print the ten first unique segment ids in train_df, val_df and test_df\n",
    "print(\"Train segment IDs:\", train_df['segment_id'].unique()[:10])\n",
    "print(\"Validation segment IDs:\", val_df['segment_id'].unique()[:10])\n",
    "print(\"Test segment IDs:\", test_df['segment_id'].unique()[:10])\n",
    "#print length of each dataframe\n",
    "print(\"Train dataframe length:\", len(train_df))\n",
    "print(\"Validation dataframe length:\", len(val_df))\n",
    "print(\"Test dataframe length:\", len(test_df))\n",
    "#print the intervals of segment IDs for each split\n",
    "print(\"Train segment ID range:\", train_df['segment_id'].min(), \"-\", train_df['segment_id'].max())\n",
    "print(\"Validation segment ID range:\", val_df['segment_id'].min(), \"-\", val_df['segment_id'].max())\n",
    "print(\"Test segment ID range:\", test_df['segment_id'].min(), \"-\", test_df['segment_id'].max())\n",
    "print(train_df.head())\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a10780",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(f\"{SPLITS_DIR}/train.parquet\", index=False)\n",
    "val_df.to_parquet(f\"{SPLITS_DIR}/val.parquet\", index=False)\n",
    "test_df.to_parquet(f\"{SPLITS_DIR}/test.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
